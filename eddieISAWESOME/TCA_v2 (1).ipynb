{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157fd580-1c31-451a-bac1-768b6242688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "#from coinmetrics.api_client import CoinMetricsClient\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#Talos\n",
    "sys.path.append(os.path.expanduser(\"~\") + \"/anchorage/source/python/trading/agency_desk/lib/\")\n",
    "import talos_utils\n",
    "\n",
    "#Coinmetrics\n",
    "path = os.path.expanduser(\"~\") + \"/jupyter-server/transferapi/\"\n",
    "sys.path.append(path)\n",
    "#import transferapi_lib\n",
    "key_folder = path + \"./key/\"\n",
    "#key_file = key_folder + \"coin_metrics.key\"\n",
    "#coinmetrics_key, null_key = transferapi_lib.load_revenue_key(key_file)\n",
    "#client = CoinMetricsClient(coinmetrics_key, verbose=False)\n",
    "\n",
    "## Talos Env ##\n",
    "env = \"x\"\n",
    "##############\n",
    "\n",
    "if env == \"wl\":\n",
    "    talos_adv_api = 'ANC0ASVTOGM0'\n",
    "    talos_adv_secret_api = '8myg2ro5bf2pzfx4m79u9yh501e09nky'\n",
    "    host_wl = \"tal-160.prod.talostrading.com\"\n",
    "    talos = talos_utils.Talos(talos_adv_api, talos_adv_secret_api, host_wl)   \n",
    "else:   \n",
    "    talos_api = 'ANC80D4RI4DL'\n",
    "    talos_secret = 'mv1ahb471yqfij1lt9g8bamhokibonwq'\n",
    "    host = \"tal-42.prod.talostrading.com\"\n",
    "    talos = talos_utils.Talos(talos_api, talos_secret, host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba0ec97-d0e1-4565-9a64-88cb186e25ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multi_order_fills(all_orders):\n",
    "    combined_df = pd.DataFrame()  # Initialize an empty dataframe to store the combined data\n",
    "    for identifier in all_orders:\n",
    "        # Call run_function for each identifier and get the dataframe\n",
    "        try:\n",
    "            df = talos.get_trade_fills(order_id=identifier)\n",
    "            df['Amount'] = df['Amount'].astype(float)\n",
    "            df['Fee'] = df['Fee'].astype(float)\n",
    "            df['Quantity'] = df['Quantity'].astype(float)\n",
    "            df[\"amount_less_fees\"] = df[\"Amount\"] - df[\"Fee\"]\n",
    "            # Concatenate the dataframe to the combined dataframe\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            time.sleep(0.100)\n",
    "        except Exception as e:\n",
    "            err_str = f\"ERROR during get_trade_fills for orderID {identifier}: {str(e)}\\n\\n\"\n",
    "            print(err_str)\n",
    "    if \"Timestamp\" in combined_df.columns:\n",
    "        combined_df = combined_df.set_index('Timestamp')\n",
    "        combined_df = combined_df.sort_index()\n",
    "    return combined_df\n",
    "\n",
    "def fills_by_dealer(df, asset, dealer_cutoff_start=None, dealer_cutoff_end=None):\n",
    "    if dealer_cutoff_start and dealer_cutoff_end is not None:\n",
    "        filtered_df = df[(df.index >= dealer_cutoff_start) & (df.index < dealer_cutoff_end)]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    # Group by dealer\n",
    "    df_by_dealer = filtered_df.groupby(\"Market\")[[\"amount_less_fees\", \"Quantity\"]].sum().reset_index()\n",
    "    df_count = filtered_df.groupby(\"Market\")[\"OrderID\"].count().reset_index()\n",
    "    df_count = df_count.rename(columns={\"OrderID\": \"fill_count\"})\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.8f}'.format\n",
    "    amount = filtered_df['amount_less_fees'].sum()\n",
    "    qty = filtered_df['Quantity'].sum()\n",
    "    exec_price = amount / qty\n",
    "\n",
    "    summary_str = f\"USD Amount: ${amount:,.2f}\\nQuantity: {qty:,.4f} {asset}\\nExecution Price: ${exec_price:,.2f}\\n\"\n",
    "    summary_df = df_by_dealer.merge(df_count)\n",
    "    return filtered_df, summary_str, summary_df, exec_price\n",
    "\n",
    "\n",
    "def vwap(x):\n",
    "    total_volume = x[\"amount\"].sum()\n",
    "    return (x['price'] * x[\"amount\"]).sum() / total_volume\n",
    "\n",
    "def vwap_talos(x):\n",
    "    total_volume = x[\"Size\"].sum()\n",
    "    return (x['Price'] * x[\"Size\"]).sum() / total_volume\n",
    "\n",
    "def add_calculations(df):\n",
    "    df = df.copy()\n",
    "    df[\"vwas\"] = (df[\"Quantity\"] * df[\"bps_spread_to_ref\"]).cumsum() / df[\"Quantity\"].cumsum()\n",
    "    df[\"cum_qty\"] = df[\"Quantity\"].cumsum()\n",
    "    \n",
    "    df['rolling_avg_spread'] = df['bps_spread_to_ref'].rolling(len(df), min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def resample_exchange_trades(exchange_trades):\n",
    "    # Convert column name to match Talos API output and set as index\n",
    "    exchange_trades = exchange_trades.rename(columns={\"time\": \"Timestamp\"})\n",
    "    exchange_trades = exchange_trades.set_index('Timestamp').copy()\n",
    "    \n",
    "    # Convert timestamp from UTC to EST \n",
    "    exchange_trades.index = exchange_trades.index.tz_convert(\"US/Eastern\").tz_localize(None)\n",
    "    \n",
    "    # Resample CB trades dataset to VWAP price across each 1S interval. Fill forward where there are no trades for an interval\n",
    "    exchange_trades_resampled = exchange_trades.resample(\"500ms\").apply(vwap)\n",
    "    exchange_trades = pd.DataFrame(exchange_trades_resampled, columns=[\"vwap\"])\n",
    "    exchange_trades = exchange_trades.ffill()\n",
    "    \n",
    "    return exchange_trades\n",
    "    \n",
    "def calculate_spread_to_cb(all_dealer_fills, exchange_trades):\n",
    "    # Convert timestamps to int64 (idk if this is needed but I was getting errors)\n",
    "    all_dealer_fills.index.astype(np.int64) \n",
    "    exchange_trades.index.astype(np.int64) \n",
    "\n",
    "    # Merge dealer fills df with CB 1s interval VWAP df\n",
    "    merged_df = pd.merge_asof(all_dealer_fills, exchange_trades, left_index=True, right_index=True, direction='nearest')\n",
    "    \n",
    "    # Calculate spread of fills to CB in bps\n",
    "    cols = ['PriceAllIn', 'vwap', 'Quantity']\n",
    "    merged_df[cols] = merged_df[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    merged_df[\"bps_spread_to_ref\"] = ((merged_df[\"PriceAllIn\"] - merged_df[\"vwap\"]) / merged_df[\"vwap\"]) * 10000\n",
    "    merged_df[\"bps_spread_to_ref\"] = pd.to_numeric(merged_df[\"bps_spread_to_ref\"], errors='coerce')\n",
    "\n",
    "    # Calculate Average and Volume weighted Spread for all fills\n",
    "    avg_spread_to_ref = merged_df['bps_spread_to_ref'].mean()\n",
    "    total_volume = merged_df['Quantity'].sum()\n",
    "    vwas = (merged_df['bps_spread_to_ref'] * merged_df['Quantity']).sum() / total_volume\n",
    "    summary_str = f\"Mean Spread to Reference px: {avg_spread_to_ref:,.4f} bps\\nVolume-weighted Avg Spread to Reference px: {vwas:,.4f} bps\\n\"\n",
    "   \n",
    "    return merged_df, summary_str\n",
    "\n",
    "def datetime_to_str(timestamp):\n",
    "    utc_datetime = pytz.timezone('US/Eastern').localize(timestamp).astimezone(pytz.utc)\n",
    "    utc_string = utc_datetime.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    \n",
    "    return utc_string\n",
    "\n",
    "def convert_to_et(datetime_string):\n",
    "    datetime_obj = datetime.strptime(datetime_string, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    datetime_et = pytz.utc.localize(datetime_obj).astimezone(eastern)\n",
    "    \n",
    "    return datetime_et.replace(tzinfo=None)\n",
    "\n",
    "def get_exchange_trades_df(symbol, market, startDate, endDate):\n",
    "    # get talos market data, convert to df\n",
    "    trades = talos.get_market_trades(symbol, market, startDate, endDate)\n",
    "    df = pd.DataFrame(trades)\n",
    "    # set timestamp as index, convert to EST\n",
    "    df['TransactTime'] = df['TransactTime'].apply(lambda x: convert_to_et(x))\n",
    "    df = df.drop(columns=['Timestamp'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def resample_exchange_trades_talos(exchange_trades):\n",
    "    # Convert column name to match Talos API output and set as index\n",
    "    exchange_trades = exchange_trades.rename(columns={\"TransactTime\": \"Timestamp\"})\n",
    "    exchange_trades = exchange_trades.set_index('Timestamp').copy()\n",
    "    \n",
    "    # Resample CB trades dataset to VWAP price across each 1S interval. Fill forward where there are no trades for an interval\n",
    "    exchange_trades[\"Price\"] = exchange_trades[\"Price\"].astype(float)\n",
    "    exchange_trades[\"Size\"] = exchange_trades[\"Size\"].astype(float) \n",
    "    exchange_trades_resampled = exchange_trades.resample(\"500ms\").apply(vwap_talos)\n",
    "    exchange_trades = pd.DataFrame(exchange_trades_resampled, columns=[\"vwap_talos\"])\n",
    "    exchange_trades = exchange_trades.ffill()\n",
    "    \n",
    "    return exchange_trades\n",
    "\n",
    "def calculate_spread_to_ref(all_dealer_fills, exchange_trades):\n",
    "    # Merge dealer fills df with CB 1s interval VWAP df\n",
    "    merged_df = pd.merge_asof(all_dealer_fills, exchange_trades, left_index=True, right_index=True, direction='nearest')\n",
    "    \n",
    "    # Calculate spread of fills to CB in bps\n",
    "    cols = ['PriceAllIn', 'vwap_talos', 'Quantity']\n",
    "    merged_df[cols] = merged_df[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    merged_df[\"bps_spread_to_ref\"] = ((merged_df[\"PriceAllIn\"] - merged_df[\"vwap_talos\"]) / merged_df[\"vwap_talos\"]) * 10000\n",
    "    merged_df[\"bps_spread_to_ref\"] = pd.to_numeric(merged_df[\"bps_spread_to_ref\"], errors='coerce')\n",
    "\n",
    "    # Calculate Average and Volume weighted Spread for all fills\n",
    "    avg_spread_to_ref = merged_df['bps_spread_to_ref'].mean()\n",
    "    total_volume = merged_df['Quantity'].sum()\n",
    "    vwas = (merged_df['bps_spread_to_ref'] * merged_df['Quantity']).sum() / total_volume\n",
    "    summary_str = f\"Mean Spread to Reference px: {avg_spread_to_ref:,.4f} bps\\nVolume-weighted Avg Spread to Reference px: {vwas:,.4f} bps\\n\"\n",
    "    \n",
    "    return merged_df, summary_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968389ef-bfeb-48ed-ae29-1a25fff6b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USD Amount: $237,137,649.78\n",
      "Quantity: 3,879.3415 BTC\n",
      "Execution Price: $61,128.32\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market</th>\n",
       "      <th>amount_less_fees</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>fill_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cumberland</td>\n",
       "      <td>116,620,952.63917500</td>\n",
       "      <td>1,911.29260102</td>\n",
       "      <td>4114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>janestreet</td>\n",
       "      <td>92,407,161.95429581</td>\n",
       "      <td>1,499.96042852</td>\n",
       "      <td>12985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wintermute</td>\n",
       "      <td>28,109,535.19000000</td>\n",
       "      <td>468.08850902</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Market     amount_less_fees       Quantity  fill_count\n",
       "0  cumberland 116,620,952.63917500 1,911.29260102        4114\n",
       "1  janestreet  92,407,161.95429581 1,499.96042852       12985\n",
       "2  wintermute  28,109,535.19000000   468.08850902         677"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LIVE ORDER DATA ##\n",
    "# Add OrderID & date filters\"\n",
    "all_orders = [\"bb663745-b76e-4f56-9f86-7b765c1d537f\",\n",
    "\"effd4a96-fc28-4189-9b1b-e4335e476d71\",\n",
    "\"544484a3-a584-416f-afac-80258d3e7fa7\",\n",
    "\"283f296c-0f98-4ab5-ab77-f4f8548a95fc\",\n",
    "\"d6b16a5c-0454-43ff-946e-8514f53c52e5\",\n",
    "\"c00d865b-c86c-4b71-ba35-d98f627bca23\",\n",
    "\"4278af32-ad52-4e3c-80cc-4b43611f4d63\",\n",
    "\"b850a4f2-14a2-4040-bc24-8dac9f580bb4\"]\n",
    "\n",
    "# datetime(year, month, day, hour, minute, second, microsecond) IN EST!!!\n",
    "dealer_cutoff_start = datetime(2024, 9, 18, 9, 0, 0, 0)\n",
    "dealer_cutoff_end = datetime(2024, 9, 19, 13, 0, 0, 0)\n",
    "\n",
    "# Run fill data for each order in list\n",
    "all_dealer_fills = multi_order_fills(all_orders)\n",
    "filtered_df, summary_str, summary_df, exec_price = fills_by_dealer(all_dealer_fills, \"BTC\", dealer_cutoff_start, dealer_cutoff_end)\n",
    "# filtered_df, summary_str, summary_df = fills_by_dealer(combined_df)\n",
    "\n",
    "print(summary_str)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81f990db-d9da-46fb-8056-0a8bc25e6757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1055334/3792716168.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  symbol = all_dealer_fills.Symbol[0]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Talos' object has no attribute 'get_market_trades'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1055334/3792716168.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# get exchange trades\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mexchange_trades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exchange_trades_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartDate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mexchange_trades_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample_exchange_trades_talos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexchange_trades\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1055334/617058208.py\u001b[0m in \u001b[0;36mget_exchange_trades_df\u001b[0;34m(symbol, market, startDate, endDate)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_exchange_trades_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartDate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# get talos market data, convert to df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mtrades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtalos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_market_trades\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartDate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrades\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# set timestamp as index, convert to EST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Talos' object has no attribute 'get_market_trades'"
     ]
    }
   ],
   "source": [
    "#update host for Talos market data endpoint and re-initialize talos_utils\n",
    "host_market_data = \"talostrading.com\"\n",
    "talos_adv_api = 'ANC8QX7D6WRE'\n",
    "talos_adv_secret_api = 'nqxfvg2xg9sjpdglo5ul5ydepzpv3h9r'\n",
    "talos = talos_utils.Talos(talos_adv_api, talos_adv_secret_api, host_market_data)\n",
    "\n",
    "# get data from order fills df\n",
    "symbol = all_dealer_fills.Symbol[0]\n",
    "first_fill = all_dealer_fills.index[0].to_pydatetime() - timedelta(minutes=0.1)\n",
    "last_fill = all_dealer_fills.index.max().to_pydatetime() + timedelta(minutes=0.5)\n",
    "\n",
    "# enter params for market data\n",
    "market = \"coinbase,gemini,kraken\"\n",
    "startDate = datetime_to_str(first_fill)\n",
    "endDate = datetime_to_str(last_fill)\n",
    "\n",
    "# get exchange trades\n",
    "exchange_trades = get_exchange_trades_df(symbol, market, startDate, endDate)\n",
    "exchange_trades_resampled = resample_exchange_trades_talos(exchange_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "225d7a36-5b23-43cb-90c7-76eb03a30560",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exchange_trades_resampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1055334/1850366191.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspread_summary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_spread_to_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_dealer_fills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexchange_trades_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspread_summary_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exchange_trades_resampled' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df, spread_summary_str = calculate_spread_to_ref(all_dealer_fills, exchange_trades_resampled)\n",
    "spread_summary_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96214067-85c3-4d9f-b077-fb57043526ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Ad Hoc Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95280dc3-2188-4833-9c42-e0c8512d372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('COINBASE_MKRUSD, 1S - Sheet1.csv')\n",
    "exchange_df = df[['time', 'close']].copy()\n",
    "exchange_df[\"time\"] = pd.to_datetime(exchange_df[\"time\"])\n",
    "exchange_df = exchange_df.set_index('time')\n",
    "exchange_df.index = exchange_df.index.tz_convert(\"US/Eastern\").tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3ee46-5301-41c2-bedb-b70782193e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b34640-3bf3-4a2e-b620-e6b33378c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_fills = all_dealer_fills[['Price', 'Quantity']].copy()\n",
    "order_fills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf55252-0aae-4ce3-b19b-a4f63a7ddf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge_asof(order_fills, exchange_df, left_index=True, right_index=True, direction='forward')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49690920-8898-46cb-8be2-029f3be57aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/home/michael_marano_anchorlabs_com/Quant_Research/csv_files/tca_test_mkr.csv'\n",
    "merged_df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47335ee-add9-491f-9c85-573710e6a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIVE ORDER DATA ##\n",
    "# Add OrderID & date filters\n",
    "all_orders = [\"0cc01f4e-d5bd-436a-80a6-d90f5807d3c2\",\n",
    "             ]\n",
    "    \n",
    "# datetime(year, month, day, hour, minute, second, microsecond) IN EST!!!\n",
    "dealer_cutoff_start = datetime(2024, 5, 20, 10, 0, 0, 0)\n",
    "dealer_cutoff_end = datetime(2024, 5, 21, 23, 0, 0, 0)\n",
    "\n",
    "# Run fill data for each order in list\n",
    "all_dealer_fills = multi_order_fills(all_orders)\n",
    "filtered_df, summary_str, summary_df, exec_price = fills_by_dealer(all_dealer_fills, \"ETH\", dealer_cutoff_start, dealer_cutoff_end)\n",
    "# filtered_df, summary_str, summary_df = fills_by_dealer(combined_df)\n",
    "\n",
    "print(summary_str)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6834a-3a24-4c1d-9cf1-507534bb6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('COINBASE_ETHUSD, 1S (1).csv')\n",
    "exchange_df = df[['time', 'close']].copy()\n",
    "exchange_df[\"time\"] = pd.to_datetime(exchange_df[\"time\"])\n",
    "exchange_df = exchange_df.set_index('time')\n",
    "exchange_df.index = exchange_df.index.tz_convert(\"US/Eastern\").tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199254f9-8868-42b4-a217-1a3342f95666",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_fills = all_dealer_fills[['Price', 'Quantity']].copy()\n",
    "merged_df = pd.merge_asof(order_fills, exchange_df, left_index=True, right_index=True, direction='forward')\n",
    "file_name = '/home/michael_marano_anchorlabs_com/Quant_Research/csv_files/tca_test_eth.csv'\n",
    "merged_df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866093c0-b350-4055-b30c-393c31dfc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "talos_adv_api = 'ANC8QX7D6WRE'\n",
    "talos_adv_secret_api = 'nqxfvg2xg9sjpdglo5ul5ydepzpv3h9r'\n",
    "host_wl = \"talostrading.com\"\n",
    "talos_wl = talos_utils.Talos(talos_adv_api, talos_adv_secret_api, host_wl)\n",
    "\n",
    "symbol = \"MKR-USD\"\n",
    "market = \"coinbase\"\n",
    "\n",
    "startDate = \"2024-05-22T01:01:00.000000Z\"\n",
    "endDate = \"2024-05-25T02:01:00.000000Z\"\n",
    "\n",
    "trades = talos_wl.get_market_trades(symbol, market, startDate, endDate, limit=None, after=None, orderBy=\"-TransactTime\")\n",
    "df = pd.DataFrame(trades)\n",
    "# talos_wl.get_market_tradesv2(symbol, market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc762940-c419-4dbb-a8f8-639b26ed8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_et(datetime_string):\n",
    "    datetime_obj = datetime.strptime(datetime_string, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    datetime_et = pytz.utc.localize(datetime_obj).astimezone(eastern)\n",
    "    return datetime_et.replace(tzinfo=None)\n",
    "\n",
    "# Apply the function to the DataFrame column\n",
    "df['TransactTime'] = df['TransactTime'].apply(lambda x: convert_to_et(x))\n",
    "df = df.set_index('TransactTime')\n",
    "df = df.drop(columns=['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d8972-a922-4aba-9f07-1aeea3aaa4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3287a9a-cbbb-4c7c-bf9a-c588bc39e9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2a298220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/eddie_akers_anchorlabs_com/.local/lib/python3.9/site-packages/google/auth/_default.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">76</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a </span><span style=\"color: #808000; text-decoration-color: #808000\">\"quota exceeded\"</span><span style=\"color: #808000; text-decoration-color: #808000\"> or </span><span style=\"color: #808000; text-decoration-color: #808000\">\"API not enabled\"</span><span style=\"color: #808000; text-decoration-color: #808000\"> error. See the following page for troubleshooting: </span><span style=\"color: #808000; text-decoration-color: #808000; text-decoration: underline\">https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/eddie_akers_anchorlabs_com/.local/lib/python3.9/site-packages/google/auth/\u001b[0m\u001b[1;33m_default.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m76\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \u001b[0m\u001b[33m\"quota exceeded\"\u001b[0m\u001b[33m or \u001b[0m\u001b[33m\"API not enabled\"\u001b[0m\u001b[33m error. See the following page for troubleshooting: \u001b[0m\u001b[4;33mhttps://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Orders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_135872/1591945626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_current_sheet_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0morders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Orders'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime as dt\n",
    "import logging\n",
    "import time\n",
    "\n",
    "#from coinmetrics.api_client import CoinMetricsClient\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~\") + \"/anchorage/source/python/quant_lib/anchoragequantlib\")\n",
    "import google_sheet_utility as aql_google_sheet_utility\n",
    "import utils as aql_utils\n",
    "\n",
    "os.environ[\"GOOGLE_SHEET_KEY\"] = \"projects/375663101687/secrets/trading_gsheet_auth_token/versions/1\"\n",
    "google_sheet_key = aql_utils.read_secret(os.environ.get(\"GOOGLE_SHEET_KEY\"))\n",
    "gsheet_key = json.loads(google_sheet_key)\n",
    "worksheet_name = \"Dealer Arb Calc\"\n",
    "tab_name = \"orders\"\n",
    "gsu = aql_google_sheet_utility.GoogleSheetUtility(gsheet_key, worksheet_name)\n",
    "\n",
    "df = gsu._get_current_sheet_df(tab_name, 0)\n",
    "orders = df.Orders.tolist()\n",
    "\n",
    "\n",
    "\n",
    "#Talos\n",
    "sys.path.append(os.path.expanduser(\"~\") + \"/anchorage/source/python/trading/agency_desk/lib/\")\n",
    "import talos_utils\n",
    "\n",
    "#Coinmetrics\n",
    "path = os.path.expanduser(\"~\") + \"/jupyter-server/transferapi/\"\n",
    "sys.path.append(path)\n",
    "#import transferapi_lib\n",
    "key_folder = path + \"./key/\"\n",
    "#key_file = key_folder + \"coin_metrics.key\"\n",
    "#coinmetrics_key, null_key = transferapi_lib.load_revenue_key(key_file)\n",
    "#client = CoinMetricsClient(coinmetrics_key, verbose=False)\n",
    "\n",
    "## Talos Env ##\n",
    "env = \"wl\"\n",
    "##############\n",
    "talos_adv_api = 'ANC0ASVTOGM0'\n",
    "talos_adv_secret_api = '8myg2ro5bf2pzfx4m79u9yh501e09nky'\n",
    "host_wl = \"tal-160.prod.talostrading.com\"\n",
    "talos = talos_utils.Talos(talos_adv_api, talos_adv_secret_api, host_wl)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_order_fills(all_orders):\n",
    "    combined_df = pd.DataFrame()  # Initialize an empty dataframe to store the combined data\n",
    "    for identifier in all_orders:\n",
    "        # Call run_function for each identifier and get the dataframe\n",
    "        try:\n",
    "            df = talos.get_trade_fills(order_id=identifier)\n",
    "            df['Amount'] = df['Amount'].astype(float)\n",
    "            df['Fee'] = df['Fee'].astype(float)\n",
    "            df['Quantity'] = df['Quantity'].astype(float)\n",
    "            df[\"amount_less_fees\"] = df[\"Amount\"] - df[\"Fee\"]\n",
    "            # Concatenate the dataframe to the combined dataframe\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            time.sleep(0.100)\n",
    "        except Exception as e:\n",
    "            err_str = f\"ERROR during get_trade_fills for orderID {identifier}: {str(e)}\\n\\n\"\n",
    "            print(err_str)\n",
    "    if \"Timestamp\" in combined_df.columns:\n",
    "        combined_df = combined_df.set_index('Timestamp')\n",
    "        combined_df = combined_df.sort_index()\n",
    "    return combined_df\n",
    "\n",
    "def fills_by_dealer(df, asset, dealer_cutoff_start=None, dealer_cutoff_end=None):\n",
    "    if dealer_cutoff_start and dealer_cutoff_end is not None:\n",
    "        filtered_df = df[(df.index >= dealer_cutoff_start) & (df.index < dealer_cutoff_end)]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    # Group by dealer\n",
    "    df_by_dealer = filtered_df.groupby(\"Market\")[[\"amount_less_fees\", \"Quantity\"]].sum().reset_index()\n",
    "    df_count = filtered_df.groupby(\"Market\")[\"OrderID\"].count().reset_index()\n",
    "    df_count = df_count.rename(columns={\"OrderID\": \"fill_count\"})\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.8f}'.format\n",
    "    amount = filtered_df['amount_less_fees'].sum()\n",
    "    qty = filtered_df['Quantity'].sum()\n",
    "    exec_price = amount / qty\n",
    "\n",
    "    summary_str = f\"USD Amount: ${amount:,.2f}\\nQuantity: {qty:,.4f} {asset}\\nExecution Price: ${exec_price:,.2f}\\n\"\n",
    "    summary_df = df_by_dealer.merge(df_count)\n",
    "    return filtered_df, summary_str, summary_df, exec_price\n",
    "\n",
    "\n",
    "def vwap(x):\n",
    "    total_volume = x[\"amount\"].sum()\n",
    "    return (x['price'] * x[\"amount\"]).sum() / total_volume\n",
    "\n",
    "def vwap_talos(x):\n",
    "    total_volume = x[\"Size\"].sum()\n",
    "    return (x['Price'] * x[\"Size\"]).sum() / total_volume\n",
    "\n",
    "def add_calculations(df):\n",
    "    df = df.copy()\n",
    "    df[\"vwas\"] = (df[\"Quantity\"] * df[\"bps_spread_to_ref\"]).cumsum() / df[\"Quantity\"].cumsum()\n",
    "    df[\"cum_qty\"] = df[\"Quantity\"].cumsum()\n",
    "    \n",
    "    df['rolling_avg_spread'] = df['bps_spread_to_ref'].rolling(len(df), min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def resample_exchange_trades(exchange_trades):\n",
    "    # Convert column name to match Talos API output and set as index\n",
    "    exchange_trades = exchange_trades.rename(columns={\"time\": \"Timestamp\"})\n",
    "    exchange_trades = exchange_trades.set_index('Timestamp').copy()\n",
    "    \n",
    "    # Convert timestamp from UTC to EST \n",
    "    exchange_trades.index = exchange_trades.index.tz_convert(\"US/Eastern\").tz_localize(None)\n",
    "    \n",
    "    # Resample CB trades dataset to VWAP price across each 1S interval. Fill forward where there are no trades for an interval\n",
    "    exchange_trades_resampled = exchange_trades.resample(\"500ms\").apply(vwap)\n",
    "    exchange_trades = pd.DataFrame(exchange_trades_resampled, columns=[\"vwap\"])\n",
    "    exchange_trades = exchange_trades.ffill()\n",
    "    \n",
    "    return exchange_trades\n",
    "    \n",
    "def calculate_spread_to_cb(all_dealer_fills, exchange_trades):\n",
    "    # Convert timestamps to int64 (idk if this is needed but I was getting errors)\n",
    "    all_dealer_fills.index.astype(np.int64) \n",
    "    exchange_trades.index.astype(np.int64) \n",
    "\n",
    "    # Merge dealer fills df with CB 1s interval VWAP df\n",
    "    merged_df = pd.merge_asof(all_dealer_fills, exchange_trades, left_index=True, right_index=True, direction='nearest')\n",
    "    \n",
    "    # Calculate spread of fills to CB in bps\n",
    "    cols = ['PriceAllIn', 'vwap', 'Quantity']\n",
    "    merged_df[cols] = merged_df[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    merged_df[\"bps_spread_to_ref\"] = ((merged_df[\"PriceAllIn\"] - merged_df[\"vwap\"]) / merged_df[\"vwap\"]) * 10000\n",
    "    merged_df[\"bps_spread_to_ref\"] = pd.to_numeric(merged_df[\"bps_spread_to_ref\"], errors='coerce')\n",
    "\n",
    "    # Calculate Average and Volume weighted Spread for all fills\n",
    "    avg_spread_to_ref = merged_df['bps_spread_to_ref'].mean()\n",
    "    total_volume = merged_df['Quantity'].sum()\n",
    "    vwas = (merged_df['bps_spread_to_ref'] * merged_df['Quantity']).sum() / total_volume\n",
    "    summary_str = f\"Mean Spread to Reference px: {avg_spread_to_ref:,.4f} bps\\nVolume-weighted Avg Spread to Reference px: {vwas:,.4f} bps\\n\"\n",
    "   \n",
    "    return merged_df, summary_str\n",
    "\n",
    "def datetime_to_str(timestamp):\n",
    "    utc_datetime = pytz.timezone('US/Eastern').localize(timestamp).astimezone(pytz.utc)\n",
    "    utc_string = utc_datetime.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    \n",
    "    return utc_string\n",
    "\n",
    "def convert_to_et(datetime_string):\n",
    "    datetime_obj = datetime.strptime(datetime_string, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    datetime_et = pytz.utc.localize(datetime_obj).astimezone(eastern)\n",
    "    \n",
    "    return datetime_et.replace(tzinfo=None)\n",
    "\n",
    "def get_exchange_trades_df(symbol, market, startDate, endDate):\n",
    "    # get talos market data, convert to df\n",
    "    trades = talos.get_market_trades(symbol, market, startDate, endDate)\n",
    "    df = pd.DataFrame(trades)\n",
    "    # set timestamp as index, convert to EST\n",
    "    df['TransactTime'] = df['TransactTime'].apply(lambda x: convert_to_et(x))\n",
    "    df = df.drop(columns=['Timestamp'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def resample_exchange_trades_talos(exchange_trades):\n",
    "    # Convert column name to match Talos API output and set as index\n",
    "    exchange_trades = exchange_trades.rename(columns={\"TransactTime\": \"Timestamp\"})\n",
    "    exchange_trades = exchange_trades.set_index('Timestamp').copy()\n",
    "    \n",
    "    # Resample CB trades dataset to VWAP price across each 1S interval. Fill forward where there are no trades for an interval\n",
    "    exchange_trades[\"Price\"] = exchange_trades[\"Price\"].astype(float)\n",
    "    exchange_trades[\"Size\"] = exchange_trades[\"Size\"].astype(float) \n",
    "    exchange_trades_resampled = exchange_trades.resample(\"500ms\").apply(vwap_talos)\n",
    "    exchange_trades = pd.DataFrame(exchange_trades_resampled, columns=[\"vwap_talos\"])\n",
    "    exchange_trades = exchange_trades.ffill()\n",
    "    \n",
    "    return exchange_trades\n",
    "\n",
    "def calculate_spread_to_ref(all_dealer_fills, exchange_trades):\n",
    "    # Merge dealer fills df with CB 1s interval VWAP df\n",
    "    merged_df = pd.merge_asof(all_dealer_fills, exchange_trades, left_index=True, right_index=True, direction='nearest')\n",
    "    \n",
    "    # Calculate spread of fills to CB in bps\n",
    "    cols = ['PriceAllIn', 'vwap_talos', 'Quantity']\n",
    "    merged_df[cols] = merged_df[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    merged_df[\"bps_spread_to_ref\"] = ((merged_df[\"PriceAllIn\"] - merged_df[\"vwap_talos\"]) / merged_df[\"vwap_talos\"]) * 10000\n",
    "    merged_df[\"bps_spread_to_ref\"] = pd.to_numeric(merged_df[\"bps_spread_to_ref\"], errors='coerce')\n",
    "\n",
    "    # Calculate Average and Volume weighted Spread for all fills\n",
    "    avg_spread_to_ref = merged_df['bps_spread_to_ref'].mean()\n",
    "    total_volume = merged_df['Quantity'].sum()\n",
    "    vwas = (merged_df['bps_spread_to_ref'] * merged_df['Quantity']).sum() / total_volume\n",
    "    summary_str = f\"Mean Spread to Reference px: {avg_spread_to_ref:,.4f} bps\\nVolume-weighted Avg Spread to Reference px: {vwas:,.4f} bps\\n\"\n",
    "    \n",
    "    return merged_df, summary_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9fd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['64bf5a2d-6bec-4942-adb4-dab7e7258cca',\n",
       " 'f3c7aedc-f72c-4192-a64f-d67520c1ff09',\n",
       " '03369454-1fbf-4fbf-ac0a-6299af6ccf95',\n",
       " 'b1fa01b1-7846-4adf-8b78-c1b7f2de4c26',\n",
       " '831dcad3-ea98-4d34-bbdd-ae82d748730a',\n",
       " 'f726aafd-b442-40bf-9a8c-77918fcadb68',\n",
       " '16c57372-e1b7-45fe-ac0e-165c15a3f502',\n",
       " '8cfed93d-d083-4448-a834-770e58928591',\n",
       " '632816e5-13d4-41d1-a1fa-8302cf4a1164',\n",
       " 'ce1e21ad-693f-4445-9eed-1e9c6f04f2c2',\n",
       " 'd40ad82c-f8c1-490a-8237-d335765e1380',\n",
       " '17105e19-1ad8-4c3b-8b95-a5417674b85b',\n",
       " '0a0a3d6e-3ef7-4bb0-8878-df18ebe2c266',\n",
       " 'ecae2009-01b4-406b-8aec-ddaa00e92faf',\n",
       " 'be67f70d-ba2a-4dca-a8db-aa13390bc8d4',\n",
       " '86453a1d-c71d-4ee6-9bca-5cc72222366a',\n",
       " '4e6f4ff3-869a-4a36-b049-3c30ef4809f1',\n",
       " '58862d86-5c1e-4e60-9980-4554706c9767',\n",
       " 'dd65cde6-c89d-43c2-a2e8-ed5e30e344ba',\n",
       " 'cc6e9b78-df5d-46f6-8924-61d95599818b',\n",
       " 'b0e349f6-d48f-4d5c-a3cc-cdd1a4093500',\n",
       " '2ccb48d4-a243-43e5-a7f1-a3448072286e',\n",
       " '541bb447-e698-463b-b1b5-e1682b954a56',\n",
       " '0244a577-769b-40a5-bacb-8b1b73be9c1f',\n",
       " '2cd77f64-a20a-4832-9143-13107be8a78f',\n",
       " '885071aa-b874-4258-8c81-b7298dc94a6c']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USD Amount: $354,223.21\n",
      "Quantity: 118,103.4383 BTC\n",
      "Execution Price: $3.00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market</th>\n",
       "      <th>amount_less_fees</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>fill_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>galaxy</td>\n",
       "      <td>117,060.56707044</td>\n",
       "      <td>2.00987563</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multileg</td>\n",
       "      <td>118,052.75693474</td>\n",
       "      <td>118,099.38465862</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wintermute</td>\n",
       "      <td>119,109.88700000</td>\n",
       "      <td>2.04372418</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Market  amount_less_fees         Quantity  fill_count\n",
       "0      galaxy  117,060.56707044       2.00987563          42\n",
       "1    multileg  118,052.75693474 118,099.38465862          43\n",
       "2  wintermute  119,109.88700000       2.04372418          44"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3353817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "all_suborders = []\n",
    "\n",
    "for order in orders:\n",
    "    # Fetch the order data\n",
    "    test_order = talos.get_orders(order)\n",
    "    \n",
    "    # Convert the order data to a DataFrame\n",
    "    test_synthetic = pd.DataFrame(test_order)\n",
    "    \n",
    "    # Extract and clean the 'Markets' data for this order\n",
    "    test_suborders = pd.DataFrame(test_synthetic[\"Markets\"][0]).dropna()\n",
    "    \n",
    "    # Add 'OrderID' and 'Timestamp' to each suborder\n",
    "    test_suborders['OrderID'] = order  # Assuming 'order' contains the OrderID\n",
    "    test_suborders['Timestamp'] = test_synthetic['Timestamp'].iloc[0]  # Assuming the first timestamp is relevant\n",
    "    \n",
    "    # Append the cleaned DataFrame to the list\n",
    "    all_suborders.append(test_suborders)\n",
    "\n",
    "# Concatenate all the suborders into a single DataFrame\n",
    "aggregate_df = pd.concat(all_suborders, ignore_index=True)\n",
    "\n",
    "# Reorder columns to ensure 'OrderID' and 'Timestamp' are first\n",
    "columns_order = ['OrderID', 'Timestamp'] + [col for col in aggregate_df.columns if col not in ['OrderID', 'Timestamp']]\n",
    "aggregate_df = aggregate_df[columns_order]\n",
    "\n",
    "# Display the final aggregated DataFrame\n",
    "worksheet_name = \"Dealer Arb Calc\"\n",
    "tab_name = \"talos_dump\"\n",
    "\n",
    "gsu = aql_google_sheet_utility.GoogleSheetUtility(gsheet_key, worksheet_name)\n",
    "gsu.dump_current_sheet(tab_name, aggregate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefe051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dealer</th>\n",
       "      <th>Side</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Buy QTY</th>\n",
       "      <th>Buy Asset</th>\n",
       "      <th>Sell QTY</th>\n",
       "      <th>Sell Asset</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wintermute</td>\n",
       "      <td>BUY</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>0.62017770</td>\n",
       "      <td>BTC</td>\n",
       "      <td>36,001.56666960</td>\n",
       "      <td>USD</td>\n",
       "      <td>58,050.40502037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wintermute</td>\n",
       "      <td>SELL</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>83,108.37373155</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.42354648</td>\n",
       "      <td>BTC</td>\n",
       "      <td>58,381.21543565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Galaxy</td>\n",
       "      <td>BUY</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>1.40660293</td>\n",
       "      <td>BTC</td>\n",
       "      <td>82,028.86963949</td>\n",
       "      <td>USD</td>\n",
       "      <td>58,317.00467131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Galaxy</td>\n",
       "      <td>SELL</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>35,031.69743097</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.60327270</td>\n",
       "      <td>BTC</td>\n",
       "      <td>58,069.42271874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dealer  Side   Symbol         Buy QTY Buy Asset        Sell QTY  \\\n",
       "0  Wintermute   BUY  BTC/USD      0.62017770       BTC 36,001.56666960   \n",
       "1  Wintermute  SELL  BTC/USD 83,108.37373155       USD      1.42354648   \n",
       "2      Galaxy   BUY  BTC/USD      1.40660293       BTC 82,028.86963949   \n",
       "3      Galaxy  SELL  BTC/USD 35,031.69743097       USD      0.60327270   \n",
       "\n",
       "  Sell Asset           Price  \n",
       "0        USD 58,050.40502037  \n",
       "1        BTC 58,381.21543565  \n",
       "2        USD 58,317.00467131  \n",
       "3        BTC 58,069.42271874  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df = multi_order_fills(orders)\n",
    "# Step 1: Filter only relevant columns\n",
    "relevant_columns = ['Market', 'Side', 'Currency', 'Quantity', 'Price']\n",
    "df_filtered = df[relevant_columns].copy()\n",
    "\n",
    "# Step 2: Convert 'Quantity' and 'Price' to numeric values\n",
    "df_filtered['Quantity'] = pd.to_numeric(df_filtered['Quantity'], errors='coerce')\n",
    "df_filtered['Price'] = pd.to_numeric(df_filtered['Price'], errors='coerce')\n",
    "\n",
    "# Step 3: Define the dealers of interest\n",
    "dealers = ['wintermute', 'galaxy']\n",
    "\n",
    "# Step 4: Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Step 5: Loop through each dealer\n",
    "for dealer in dealers:\n",
    "    # Filter data for the current dealer\n",
    "    dealer_data = df_filtered[df_filtered['Market'].str.lower() == dealer]\n",
    "\n",
    "    # Group by Currency and Side to net the positions\n",
    "    net_positions = dealer_data.groupby(['Currency', 'Side']).agg({\n",
    "        'Quantity': 'sum',\n",
    "        'Price': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Loop through 'BUY' and 'SELL' sides to calculate details\n",
    "    for side in ['BUY', 'SELL']:\n",
    "        side_data = net_positions[(net_positions['Currency'] == 'BTC') & \n",
    "                                  (net_positions['Side'].str.upper() == side)]\n",
    "\n",
    "        if not side_data.empty:\n",
    "            total_qty = side_data['Quantity'].sum()\n",
    "            weighted_avg_price = dealer_data[dealer_data['Side'].str.upper() == side].apply(\n",
    "                lambda x: x['Quantity'] * x['Price'], axis=1).sum() / total_qty\n",
    "\n",
    "            if side == 'BUY':\n",
    "                buy_qty = total_qty\n",
    "                sell_qty = buy_qty * weighted_avg_price  # Convert to USD\n",
    "                buy_asset = 'BTC'\n",
    "                sell_asset = 'USD'\n",
    "            else:\n",
    "                sell_qty = total_qty\n",
    "                buy_qty = sell_qty * weighted_avg_price  # Convert to USD\n",
    "                buy_asset = 'USD'\n",
    "                sell_asset = 'BTC'\n",
    "\n",
    "            # Append the result for the current dealer and side to the list\n",
    "            results.append({\n",
    "                'Dealer': dealer.capitalize(),\n",
    "                'Side': side,\n",
    "                'Symbol': 'BTC/USD',\n",
    "                'Buy QTY': buy_qty,\n",
    "                'Buy Asset': buy_asset,\n",
    "                'Sell QTY': sell_qty,\n",
    "                'Sell Asset': sell_asset,\n",
    "                'Price': weighted_avg_price\n",
    "            })\n",
    "\n",
    "# Step 6: Convert the results list to a DataFrame\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the final DataFrame\n",
    "display(result_df)\n",
    "\n",
    "worksheet_name = \"Dealer Arb Calc\"\n",
    "tab_name = \"talos_dump_sum\"\n",
    "\n",
    "gsu = aql_google_sheet_utility.GoogleSheetUtility(gsheet_key, worksheet_name)\n",
    "gsu.dump_current_sheet(tab_name, result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d1288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3aa360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
