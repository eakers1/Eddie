{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import logging\n",
    "from google.cloud import bigquery\n",
    "import warnings\n",
    "\n",
    "sys.path.append(os.environ[\"HOME\"]+\"/trading/python/\")\n",
    "from lib import aplo # type: ignore\n",
    "from lib import talos_utils # type: ignore\n",
    "from lib import vault_utils # type: ignore\n",
    "from lib import gsu # type: ignore\n",
    "from lib import utils # type: ignore\n",
    "from lib import keys_utils as keys\n",
    "# from perps_monitor import main as perps_monitor_main # type: ignore\n",
    "\n",
    "sys.path.append(os.environ[\"HOME\"] + \"/anchorage/source/python/lib/quant_lib/anchoragequantlib\")\n",
    "#import google_sheet_utility as aql_google_sheet_utility # type: ignore\n",
    "#import utils as aql_utils # type: ignore\n",
    "\n",
    "\n",
    "#logging.getLogger().setLevel(logging.INFO)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:,.8f}'.format\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GCP_PROJECT_VAR\"] = \"\"\n",
    "os.environ[\"GOOGLE_SHEET_KEY\"] = \"projects/698304263300/secrets/trading_gsheet_auth_token/versions/1\"\n",
    "\n",
    "# os.environ[\"OKX_APIKEY\"] = keys.okx_bp_read_api_key\n",
    "# os.environ[\"OKX_SECRET\"] = keys.okx_bp_read_secret\n",
    "# os.environ[\"OKX_PASSPHRASE\"] = keys.okx_bp_read_passphrase\n",
    "\n",
    "# os.environ[\"BYBIT_APIKEY\"] = keys.bybit_read_api_key\n",
    "# os.environ[\"BYBIT_SECRET\"] = keys.bybit_read_api_secret\n",
    "\n",
    "\n",
    "talos_wl_api = keys.talos_whitelabel_api_key()\n",
    "talos_wl_secret_api = keys.talos_whitelabel_api_secret()\n",
    "host_wl = keys.talos_whitelabel_host()\n",
    "\n",
    "talos_api = keys.talos_principal_api_key()\n",
    "talos_secret = keys.talos_principal_api_secret()\n",
    "host = keys.talos_principal_host()\n",
    "\n",
    "api_key_str = keys.ads_api_key()\n",
    "signing_key_str = keys.ads_signing_key()\n",
    "\n",
    "aplo_key = keys.aplo_read_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True if you want to see the logs when running the code\n",
    "debug = True\n",
    "if debug:\n",
    "    logging.basicConfig(\n",
    "        format=\"%(levelname)s (%(asctime)s): %(message)s (Line:%(lineno)d in %(funcName)s, %(filename)s))\",\n",
    "        datefmt=\"%Y/%m/%d %I:%M:%S %p\",\n",
    "        level=logging.INFO,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (2025/03/12 03:57:27 PM): Debugging initialized for AploClient (Line:29 in _setup_debugging, aplo.py))\n"
     ]
    }
   ],
   "source": [
    "talos = talos_utils.Talos(talos_api, talos_secret, host)\n",
    "talos_wl = talos_utils.Talos(talos_wl_api, talos_wl_secret_api, host_wl)\n",
    "avu = vault_utils.AnchorageVaultUtility(\n",
    "    api_key_str,\n",
    "    signing_key_str\n",
    ")\n",
    "aplo_client = aplo.AploClient(aplo_key, debug=debug)\n",
    "\n",
    "google_sheet_key = utils.read_secret(os.environ.get(\"GOOGLE_SHEET_KEY\"))\n",
    "gsheet_key = json.loads(google_sheet_key)\n",
    "worksheet_name = \"A1 Risk Dashboard\"\n",
    "trading_worksheet_name = \"A1 - Trading\"\n",
    "gsu_risk_dash = gsu.GoogleSheetUtility(gsheet_key, worksheet_name)\n",
    "gsu_trading = gsu.GoogleSheetUtility(gsheet_key, trading_worksheet_name)\n",
    "name = re.search(r'/[^/]+/([^_]+)_', os.environ[\"HOME\"]).group(1).capitalize()\n",
    "n_of_days = 7\n",
    "\n",
    "trade_sheet_names = {\n",
    "    \"counterparty\": \"Counterparty Trades\",\n",
    "    \"dealer\": \"Dealer Trades\",\n",
    "    \"exchange\": \"Exchange Trades\",\n",
    "    \"perp\": \"Perps Trades\",\n",
    "}\n",
    "\n",
    "market_translation = {\n",
    "    \"b2c2/b-2-c-2-a-1\": {\"type\": \"Dealer\", \"full_name\": \"B2C2 Overseas, Ltd.\"},\n",
    "    \"wintermute/wintermute-trading-rfq\": {\n",
    "        \"type\": \"Dealer\",\n",
    "        \"full_name\": \"Wintermute Trading LTD - API\",\n",
    "    },\n",
    "    \"okex/okx\": {\"type\": \"Exchange\", \"full_name\": \"OKX (Aux Cayes FinTech Co. Ltd.)\"},\n",
    "    \"kraken/kraken-a-1\": {\n",
    "        \"type\": \"Exchange\",\n",
    "        \"full_name\": \"Kraken (Payward Trading Ltd.)\",\n",
    "    },\n",
    "    \"coinbase/coinbase-hrp\": {\"type\": \"Exchange\", \"full_name\": \"HRP Coinbase\"},\n",
    "    \"bybit/bybit-a-1\": {\n",
    "        \"type\": \"Exchange\",\n",
    "        \"full_name\": \"Bybit (Bybit Fintech Limited)\",\n",
    "    },\n",
    "    \"gate_io/gate-io-a-1\": {\"type\": \"exchange\", \"full_name\": \"Gate.io\"},\n",
    "    \"galaxy/galaxy-trading-rfq-a-1\": {\n",
    "        \"type\": \"Dealer\",\n",
    "        \"full_name\": \"Galaxy Trading Asia Limited\",\n",
    "    },\n",
    "    \"cumberland/cumberland-trading-rfq\": {\n",
    "        \"type\": \"Dealer\",\n",
    "        \"full_name\": \"Cumberland International Trading Ltd.\",\n",
    "    },\n",
    "    \"fireblocks\": {\"type\": \"Custodian\", \"full_name\": \"A1 Fireblocks\"},\n",
    "    \"nonco/nonco-a-1\": {\n",
    "        \"type\": \"Dealer\",\n",
    "        \"full_name\": \"Nonco\",\n",
    "    },\n",
    "    \"ads\": {\"type\": \"Custodian\", \"full_name\": \"A1 ADS\"},\n",
    "    \"aplo\": {\"type\": \"Aggregator\", \"full_name\": \"APLO\"},\n",
    "    \"coinbase/coinbase-hold\": {\n",
    "        \"type\": \"Hold\",\n",
    "        \"full_name\": \"Coinbase Hold\",\n",
    "    },\n",
    "    \"cumberland/cumberland-_trading-&-rfq_\": {\n",
    "        \"type\": \"Hold\",\n",
    "        \"full_name\": \"Cumberland Hold\",\n",
    "    },\n",
    "    \"wintermute/wintermute-_trading-&-rfq_\": {\n",
    "        \"type\": \"Hold\",\n",
    "        \"full_name\": \"Wintermute Hold\",\n",
    "    },\n",
    "    \"janestreet/jane-street-_trading-&-rfq_\": {\n",
    "        \"type\": \"Hold\",\n",
    "        \"full_name\": \"Jane Street Hold\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fireblocks_balances():\n",
    "\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    query = \"\"\"\n",
    "    WITH LatestEntries AS (\n",
    "    SELECT \n",
    "        ID,\n",
    "        MAX(created_at) AS latest_created_at\n",
    "    FROM \n",
    "        `production-191601.brokerage.fireblocks_vault_balances`\n",
    "    GROUP BY \n",
    "        ID\n",
    "    )\n",
    "\n",
    "    SELECT \n",
    "    a.ID,\n",
    "    a.created_at,\n",
    "    a.available\n",
    "    FROM \n",
    "    `production-191601.brokerage.fireblocks_vault_balances` a\n",
    "    JOIN \n",
    "    LatestEntries b ON a.ID = b.ID AND a.created_at = b.latest_created_at;\n",
    "    \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "    df = query_job.result().to_dataframe()\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_aplo_balances():\n",
    "    aplo_balances = pd.DataFrame(aplo_client.get_balances())\n",
    "    aplo_balances = aplo_balances[[\"assetId\", \"quantity\",\"notional\"]]\n",
    "    return aplo_balances\n",
    "\n",
    "def get_ads_balances():    \n",
    "    data = avu.query_all_vaults()\n",
    "    df = pd.json_normalize(data, record_path=['assets'])\n",
    "    df = df[[\"assetType\", \"totalBalance.quantity\"]]   \n",
    "\n",
    "    return df\n",
    "\n",
    "def get_open_orders_wl():\n",
    "    talos_counterparties_wl = talos_wl.get_orders(statuses=\"New,PartiallyFilled\")\n",
    "\n",
    "    talos_counterparties_wl = pd.DataFrame(talos_counterparties_wl)\n",
    "    if talos_counterparties_wl.empty:\n",
    "        return pd.DataFrame(columns=['OrderID', 'Symbol', 'Side', 'Strategy', 'OrderQty', 'Currency', 'Price', 'AvgPxAllIn', 'EndTime', 'CumQty', 'SubmitTime', 'StartTime', 'DecisionStatus', 'RequestSource'])\n",
    "    df = talos_counterparties_wl .sort_values(by='EndTime', ascending=True).reset_index(drop=True)\n",
    "    df[\"EndTime\"] = pd.to_datetime(df[\"EndTime\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if \"EndTime\" in df.columns else \"\"\n",
    "    df[\"StartTime\"] = pd.to_datetime(df[\"StartTime\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if \"StartTime\" in df.columns else \"\"\n",
    "    df[\"SubmitTime\"] = pd.to_datetime(df[\"SubmitTime\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if \"SubmitTime\" in df.columns else \"\"\n",
    "    df[\"Price\"] = df[\"Price\"] if \"Price\" in df.columns else \"\"\n",
    "    df[\"AvgPxAllIn\"] = df[\"AvgPxAllIn\"] if \"AvgPxAllIn\" in df.columns else \"\"\n",
    "\n",
    "    df = df[['OrderID', 'Symbol', 'Side', 'Strategy', 'OrderQty', 'Currency', 'Price', 'AvgPxAllIn', 'EndTime', 'CumQty', 'SubmitTime', 'StartTime', 'DecisionStatus', 'RequestSource']]\n",
    "\n",
    "    return df\n",
    "def get_open_orders():\n",
    "    talos_counterparties = talos.get_orders(statuses=\"New,PartiallyFilled\")\n",
    "\n",
    "    talos_counterparties = pd.DataFrame(talos_counterparties)\n",
    "    if talos_counterparties.empty:\n",
    "        return pd.DataFrame(columns=['OrderID', 'Symbol', 'Side', 'Strategy', 'OrderQty', 'Currency', 'Price', 'AvgPxAllIn', 'EndTime', 'CumQty', 'SubmitTime', 'StartTime', 'DecisionStatus', 'RequestSource'])\n",
    "    df = talos_counterparties.sort_values(by='Timestamp', ascending=True).reset_index(drop=True)\n",
    "    df[\"EndTime\"] = pd.to_datetime(df[\"EndTime\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if \"EndTime\" in df.columns else \"\"\n",
    "    df[\"SubmitTime\"] = pd.to_datetime(df[\"SubmitTime\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if \"SubmitTime\" in df.columns else \"\"\n",
    "    df[\"StartTime\"] = pd.to_datetime(df[\"StartTime\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if \"StartTime\" in df.columns else \"\"\n",
    "    df[\"Price\"] = df[\"Price\"] if \"Price\" in df.columns else \"\"    \n",
    "    df[\"AvgPxAllIn\"] = df[\"AvgPxAllIn\"] if \"AvgPxAllIn\" in df.columns else \"\"\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_completed_orders(start_date):\n",
    "    talos_completed_wl = talos_wl.get_orders(start_date = start_date, statuses=\"DoneForDay\")\n",
    "\n",
    "    talos_completed_wl = pd.DataFrame(talos_completed_wl)\n",
    "    df = talos_completed_wl.sort_values(by='Timestamp', ascending=False).reset_index(drop=True)\n",
    "    df = df[df['SubAccount']==\"A1-Intl\"]\n",
    "    df[\"EndTime\"] = pd.to_datetime(df[\"EndTime\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if \"EndTime\" in df.columns else \"\"\n",
    "    df[\"StartTime\"] = pd.to_datetime(df[\"StartTime\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    df = df[['OrderID', 'Symbol', 'Side', 'Strategy', 'OrderQty', 'Currency', 'Price', 'AvgPxAllIn', 'EndTime', 'CumQty', 'SubmitTime', 'StartTime', 'RequestSource']]\n",
    "    return df\n",
    "\n",
    "# def get_aplo_orders():\n",
    "#     aplo_orders = pd.json_normalize(aplo_client.get_orders())\n",
    "#     df = aplo_orders[['token', 'status', 'instrument', 'classification', 'subType', 'requestedVolume', 'assetId', 'requestedPrice', 'time', 'parameters.lifespan',]]\n",
    "#     return df\n",
    "\n",
    "def get_talos_balances():\n",
    "    markets = \"kraken,okex,coinbase,wintermute,cumberland,janestreet,bybit,b2c2,nonco,galaxy,gate_io\"\n",
    "    talos_balances_wl = talos_wl.get_balances(markets=markets)\n",
    "    talos_balances_wl = pd.DataFrame(talos_balances_wl)\n",
    "    columns_to_drop = ['Status','MarketAccountID','ReconStatus']\n",
    "    talos_balances_wl = talos_balances_wl.drop(columns=columns_to_drop)\n",
    "    talos_balances_wl['AvailableAmount'] = pd.to_numeric(talos_balances_wl['AvailableAmount'], errors='coerce')\n",
    "    talos_balances_wl = talos_balances_wl[[\"Currency\", \"Market\", \"Account\", \"Amount\", \"AvailableAmount\", \"AvailableMargin\", \"OutstandingBuy\", \"OutstandingSell\"]]\n",
    "\n",
    "    return talos_balances_wl\n",
    "\n",
    "def get_balances():\n",
    "    return {\n",
    "        'fireblocks': get_fireblocks_balances(),\n",
    "        'aplo': get_aplo_balances(),\n",
    "        'ads': get_ads_balances(),\n",
    "        'talos': get_talos_balances()\n",
    "    }\n",
    "\n",
    "def process_talos_balances(df):\n",
    "    df = df.groupby([\"Account\", \"Currency\"])[[\"AvailableAmount\"]].sum().reset_index()\n",
    "    df[\"Type\"] = np.where(df[\"Account\"].str.contains('wintermute|cumberland|janestreet|b2c2|galaxy|nonco', regex=True), \"Dealer\", \"Exchange\")\n",
    "    return df\n",
    "\n",
    "def process_aplo_balances(df):\n",
    "    df[\"Account\"] = \"aplo\"\n",
    "    df[\"Type\"] = \"Aggregator\"\n",
    "    return df.rename(columns={\"assetId\":\"Currency\", \"quantity\":\"AvailableAmount\", \"notional\":\"Notional\"})\n",
    "\n",
    "def process_ads_balances(df):\n",
    "    df[\"Account\"] = \"ads\"\n",
    "    df[\"Type\"] = \"Custodian\"\n",
    "    return df.rename(columns={\"assetType\":\"Currency\", \"totalBalance.quantity\":\"AvailableAmount\"})\n",
    "\n",
    "def process_fireblocks_balances(df):\n",
    "    df[\"Account\"] = \"fireblocks\"\n",
    "    df[\"Type\"] = \"Custodian\"\n",
    "    df = df.rename(columns={\"available\":\"AvailableAmount\"})\n",
    "    df[\"Currency\"] = df[\"ID\"].str.split(\"_\").str[0]\n",
    "    return df[[\"Currency\", \"AvailableAmount\", \"Type\", \"Account\"]]\n",
    "\n",
    "def aggregated_balances(talos_balances_wl, aplo_balances, ads_balances, fireblocks_balances):\n",
    "    #balances = get_balances()\n",
    "    balances = {\n",
    "        'talos': talos_balances_wl,\n",
    "        'aplo': aplo_balances,\n",
    "        'ads': ads_balances,\n",
    "        'fireblocks': fireblocks_balances,\n",
    "    }\n",
    "    \n",
    "    processed_balances = {\n",
    "        'talos': process_talos_balances(balances['talos']),\n",
    "        'aplo': process_aplo_balances(balances['aplo']),\n",
    "        'ads': process_ads_balances(balances['ads']),\n",
    "        'fireblocks': process_fireblocks_balances(balances['fireblocks'])\n",
    "    }\n",
    "\n",
    "    balances_df = pd.concat(processed_balances.values())\n",
    "    \n",
    "    balances_df[\"Full Name\"] = balances_df[\"Account\"].apply(lambda x: market_translation.get(x, {}).get(\"full_name\", x))\n",
    "    balances_df[\"Type\"] = balances_df[\"Account\"].apply(lambda x: market_translation.get(x, {}).get(\"type\", x))\n",
    "    balances_df = balances_df[[\"Full Name\", \"Currency\",\"AvailableAmount\", \"Type\"]]\n",
    "\n",
    "    return balances_df\n",
    "\n",
    "def get_trades_sheets(sheet_names):\n",
    "\n",
    "    trades_sheets = {key: gsu_trading._get_current_sheet_df(name, 0) for key, name in sheet_names.items()}\n",
    "\n",
    "    for key in trades_sheets:\n",
    "        trades_sheets[key] = trades_sheets[key][trades_sheets[key]['Side'] != \"\"]\n",
    "\n",
    "    return trades_sheets\n",
    "\n",
    "def orders_to_book(trades_sheets, aplo_trades, talos_trades_wl):\n",
    "\n",
    "    # NOT WORKING FOR NOW\n",
    "    booked_orders = pd.concat([sheet.iloc[:,1] for sheet in trades_sheets.values()], axis=0).to_frame()\n",
    "    booked_orders = booked_orders.loc[~(booked_orders == \"\").any(axis=1)]\n",
    "    aplo_completed_orders = aplo_trades.query(\"status == 'open'\")['token'].copy()\n",
    "    talos_completed_orders = talos_trades_wl['OrderID'].copy()\n",
    "\n",
    "    all_orders = pd.concat([booked_orders, aplo_completed_orders, talos_completed_orders], axis=0)\n",
    "\n",
    "    #all_orders = all_orders.drop_duplicates(keep=False)\n",
    "    return all_orders \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (2025/03/12 03:57:30 PM): Fetchng Talos Data (Line:20 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:57:31 PM): Fetching Fireblocks Balances in BigQuery (Line:26 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:57:35 PM): Fetching Aplo Balances (Line:31 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:57:36 PM): Fetching ADS Balances (Line:36 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:57:36 PM): getting vaults path: https://api.anchorage.com/v2/vaults?limit=100 (Line:38 in _query_vaults, vault_utils.py))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (2025/03/12 03:57:38 PM): Fetching Aggregated Balances (Line:41 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:57:50 PM): Fetching Talos Open Orders (Line:46 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:58:12 PM): Fetching Talos WL Open Orders (Line:51 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:58:33 PM): Fetching Talos Completed Orders (Line:56 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:58:45 PM): Fetching Trades from spreadsheet (Line:66 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:59:30 PM): Updating timestamp (Line:71 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:59:31 PM): Updating runner (Line:74 in <module>, 2023372639.py))\n",
      "INFO (2025/03/12 03:59:31 PM): Code complete, sleeping for 60s... Zzzzz... (Line:79 in <module>, 2023372639.py))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25036/2023372639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code complete, sleeping for 60s... Zzzzz...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What a nice sleep, waking up!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mretries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_retries = 1\n",
    "retries = 0\n",
    "\n",
    "while retries < max_retries:\n",
    "    try:\n",
    "\n",
    "        utc_now = dt.datetime.now(dt.timezone.utc)\n",
    "        utc_now_formatted = utc_now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        days_ago = utc_now - dt.timedelta(days=n_of_days)\n",
    "        start_date = days_ago.strftime(\"%Y-%m-%dT%H:%M:%S.000000Z\")\n",
    "\n",
    "        # logging.info(\"Fetching Perps Data\")\n",
    "        # try:\n",
    "        #     perps_monitor_main.run(debug=debug)\n",
    "        # except Exception as e:\n",
    "        #     logging.error(f\"Error: {e}\")\n",
    "        #     logging.error(\"Error fetching Perps data\")\n",
    "        #     pass\n",
    "\n",
    "        logging.info(\"Fetchng Talos Data\")\n",
    "        talos_balances_wl = get_talos_balances()\n",
    "\n",
    "        talos_tab_name = \"talosData\"\n",
    "        gsu_risk_dash.dump_current_sheet(talos_tab_name, talos_balances_wl)\n",
    "\n",
    "        logging.info(\"Fetching Fireblocks Balances in BigQuery\")\n",
    "        fb_balance_tab_name = \"fireblocks_balances\"\n",
    "        fireblocks_balances = get_fireblocks_balances()\n",
    "        gsu_risk_dash.dump_current_sheet(fb_balance_tab_name, fireblocks_balances)\n",
    "\n",
    "        logging.info(\"Fetching Aplo Balances\")\n",
    "        aplo_balance_tab_name = \"aplo_balances\"\n",
    "        aplo_balances = get_aplo_balances()\n",
    "        gsu_risk_dash.dump_current_sheet(aplo_balance_tab_name, aplo_balances)\n",
    "\n",
    "        logging.info(\"Fetching ADS Balances\")\n",
    "        ads_balance_tab_name = \"ads_balances\"\n",
    "        ads_balances = get_ads_balances()\n",
    "        gsu_risk_dash.dump_current_sheet(ads_balance_tab_name, ads_balances)\n",
    "\n",
    "        logging.info(\"Fetching Aggregated Balances\")\n",
    "        aggregated_balances_tab_name = \"Aggregated Balances\"\n",
    "        aggregated_balances_df = aggregated_balances(talos_balances_wl, aplo_balances, ads_balances, fireblocks_balances)\n",
    "        gsu_risk_dash.dump_current_sheet(aggregated_balances_tab_name, aggregated_balances_df)\n",
    "\n",
    "        logging.info(\"Fetching Talos Open Orders\")\n",
    "        open_orders_tab_name = \"Open_Orders\"\n",
    "        talos_open_orders = get_open_orders()\n",
    "        gsu_risk_dash.dump_current_sheet(open_orders_tab_name, talos_open_orders)\n",
    "\n",
    "        logging.info(\"Fetching Talos WL Open Orders\")\n",
    "        open_order_wl_tab_name = \"Open_Orders_wl\"\n",
    "        wl_open_orders = get_open_orders_wl()\n",
    "        gsu_risk_dash.dump_current_sheet(open_order_wl_tab_name, wl_open_orders)\n",
    "\n",
    "        logging.info(\"Fetching Talos Completed Orders\")\n",
    "        completed_orders_tab_name = \"completed_orders\"\n",
    "        wl_complete_orders = get_completed_orders(start_date)\n",
    "        gsu_risk_dash.dump_current_sheet(completed_orders_tab_name, wl_complete_orders)\n",
    "\n",
    "        # logging.info(\"Fetching Aplo Orders\")\n",
    "        # aplo_orders_tab_name = \"aplo_orders\"\n",
    "        # aplo_open_orders = get_aplo_orders()\n",
    "        # gsu_risk_dash.dump_current_sheet(aplo_orders_tab_name, aplo_open_orders)\n",
    "\n",
    "        logging.info(\"Fetching Trades from spreadsheet\")\n",
    "        trades = get_trades_sheets(trade_sheet_names)\n",
    "        for key, value in trades.items():\n",
    "            gsu_risk_dash.dump_current_sheet(trade_sheet_names[key], value)\n",
    "\n",
    "        logging.info(\"Updating timestamp\")\n",
    "        gsu_risk_dash.append_to_worksheet_at_location(\"dash\", \"C1\", [[utc_now_formatted]])\n",
    "\n",
    "        logging.info(\"Updating runner\")\n",
    "        gsu_risk_dash.append_to_worksheet_at_location(\"dash\", \"E1\", [[name]])\n",
    "        gsu_risk_dash.append_to_worksheet_at_location(\"dash\", \"F1\", [[\"\"]])\n",
    "        if not debug:\n",
    "            print(\"Code complete, sleeping for 60s... Zzzzz...\")\n",
    "        logging.info(\"Code complete, sleeping for 60s... Zzzzz...\")\n",
    "        print(\"-----------------------------------------------\")\n",
    "        time.sleep(60)\n",
    "        logging.info(\"What a nice sleep, waking up!\")\n",
    "        retries = 0\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        retries += 1\n",
    "        error_msg = f\"Code stopped at {utc_now_formatted} UTC, please check. Attempt {retries}/{max_retries}. Error: {e}\"\n",
    "        logging.error(f\"Attempt {retries}/{max_retries} failed. Error: {e}\")\n",
    "        gsu_risk_dash.append_to_worksheet_at_location(\"dash\", \"F1\", [[error_msg]])\n",
    "        if retries >= max_retries:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
